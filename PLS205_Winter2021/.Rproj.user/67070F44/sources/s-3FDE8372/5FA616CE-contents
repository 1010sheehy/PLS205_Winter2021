---
title: "Lab 5. Modeling trends"
author: Daniel Runcie. Modified from labs designed by Iago Hale, Dario Cantu and Jorge
  Dubcovsky
output: 
 html_notebook:
    toc: true
    toc_float: true
---
Install new PLS205 package: 
```{r}
devtools::install_github('deruncie/PLS205_package')
```

Necessary packages:
```{r,warning=FALSE}
library(ggplot2)
library(emmeans)
library(lme4)
library(lmerTest)
library(PLS205)
```


---------

# Multiple levels of sub-samples

We've seen analyses with subsamples before (see Lab3). 
The key to a correct analysis is to declare the experimental units with the `(1|Variable)` syntax.
However, sometimes our measurements are on "subsamples of subsamples", or even a lower level of the data.

As an example, consider the experiment described in class:

40 pots are planted with pepper plants and distributed among 2 hot and 2 cold growth chambers (10 pots per chamber). 
After two weeks, 2 leaves are harvested per plant. 
RNA is extracted from each leaf and the expression of the gene sp1 is measured 3 times per RNA sample.

Here's an example data-set for this experiment:
```{r}
expression_data = read.csv('~/Desktop/R_Projects/PLS205_Winter2021/PLS205_Winter2021/data/sp1_expression.csv',stringsAsFactors = TRUE)
str(expression_data)
```


The design table for this experiment is:

## Design table:

| Structure | Variable        | Type        |# levels | EU      |
|-----------|-----------------|-------------|---------|---------|
| Treatment | Temperature     | Categorical | 2       | Chamber |
| Design    | Chamber         | Categorical | 4       |         |
|           | Pot             | Categorical | 40      |         |
|           | Plant           | Categorical | 40      |         |
|           | Leaf            | Categorical | 80      |         |
|           | RNA_measurement | Categorical | 240     |         |
| Response  | sp1_expression  | Numeric     | 240     |         |


## Writing the linear model

Following the rules defined in class and Lab3, we would write a model like:

`lmer(sp1_expression~Temperature+(1|Chamber)+Pot+Plant+Leaf)`

However, this won't work well in R for two reasons:

1. Pot and Plant are **aliased**. Every level of Pot is matched with matched with *one and only one* level of Plant, and *vice versa*. When two terms are aliased, we can only include one in the model (and we'll get the same answer whichever one we choose). 
2. The terms `Pot` (and `Plant`), `Leaf`, and `RNA_measurement` are all **nested** inside the EU term `Chamber`. Any term that is nested inside an EU must also be declared with `(1|Variable)`. More formally, by identifying a term as an EU, we're declaring it to be a **Random Effect**. Random effects are a broader concept in statistics, but for this class, remember that all EU's must be random, but not all random effects are EU's. The key here is that any Variable nested in another term that's a random effect must also be declared as a random effect.

I've introduced the terms **aliased** and **nested** above. These are important to become familiar with.

Here are R functions to check if terms are aliased or nested. 
**Note** these are all included in the `PLS205` package loaded above. In the future, you can access them directly by `library(PLS205)` The code below is just to show you how they work if you're interested. 


```{r}
is_nested = function(outer_term,inner_term,data) {
  all(colSums(table(data[[outer_term]],data[[inner_term]]) > 0L) == 1L)
}
is_aliased = function(term1, term2, data) {
  is_nested(term1,term2,data) & is_nested(term2,term1,data)
}
```

**aliased** variables have 1:1 relationships. Each level of 1 variable is paired with 1 unique level of the other variable. 
Variables that are aliased must have the same number of levels. We can check if two variables are aliased like this:

```{r}
is_aliased('Pot','Plant',expression_data)
is_aliased('Pot','Chamber',expression_data)
```

Variable2 is **nested** in Variable1 if every level of Variable2 occurs with only a single level of Variable1. 
For example, the pot named `Hot2_7` occurs in chamber `Hot2`, but not in any of the other chambers. 
We can check if one variable ("inner term") is nested in another ("outer term") like this:
```{r}
is_nested(outer_term = "Chamber",inner_term = 'Pot',data = expression_data)
is_nested(outer_term = "Chamber",inner_term = 'Temperature',data = expression_data)
```

**Note**: EU's are always nested in treatments:
```{r}
is_nested(outer_term = "Temperature", inner_term = "Chamber", data = expression_data)
```


So, looking at our design table again:

| Structure | Variable        | # levels | EU      |
|-----------|-----------------|----------|---------|
| Treatment | Temperature     | 2        | Chamber |
| Design    | Chamber         | 4        |         |
|           | Pot             | 40       |         |
|           | Plant           | 40       |         |
|           | Leaf            | 80       |         |
|           | RNA_measurement | 240      |         |
| Response  | sp1_expression  | 240      |         |

"Chamber" is declared as an EU, so it must be declared as Random to R: `(1|Random)`.
"Pot", "Plant", "Leaf", and "RNA_expression" are all **nested** in "Chamber", so all these must also be declared as Random to R.
However, "Plant" and "Pot" are **aliased**, so we can only include 1. 
And "RNA_expression" has the same number of levels as the response, so we can't include it. 
Therefore, the full model is:

```{r}
expression_model = lmer(sp1_expression ~ Temperature + (1|Chamber) + (1|Pot) + (1|Leaf), data = expression_data)
```

**Note**: In general, if you model is specified correctly, don't worry about warning messages in red like "boundary (singular)". This itself is not generally a concern.

## Diagnostics with multiple nested random variables

In Lab 3, I gave you code for doing **diagnostics on the EUs** of a model fit with lmer.
Because the coding here is a bit tricky, the following code block writes a function to make the two standard diagnostic
plots and should work for both `lm` and `lmer` models, at least for this class (they should be good in general, but I'm not sure it will work for all possible models in your own work). This function is also included in the `PLS205` package.
In `lmer` models, be sure to set the `EU` variable to the Variable name of the EUs. 
Otherwise, you'll be running the diagnostics on subsamples instead of the experimental units which is less useful.

```{r}
pls205_diagnostics = function(model_fit,EU = NULL) {
  # note: for lmer models, be sure to specify the EU that you are interested in!
  if(is(model_fit,'lm')) {
    # diagnostics for lm-type model
    eu_data = data.frame(fitted = fitted(model_fit),EU_std_resid = rstandard(model_fit))
  } else if(is(model_fit,'lmerMod')) {
    if(is.null(EU)) {
      # plot observations
      eu_data = data.frame(fitted = fitted(model_fit),EU_std_resid = resid(model_fit))
    } else {
      # plot estimated values of EU
      if(!EU %in% all.vars(formula(model_fit))) stop(sprintf('Your EU (%s) is not in the model you provided',EU))
      eu_data = data.frame(EU_obs = predict(model_fit,re.form = formula(sprintf('~(1|%s)',EU))),fitted = predict(model_fit,re.form=NA),model_fit@frame)
      eu_data = eu_data[!duplicated(eu_data[[EU]]),]
      eu_data = eu_data[order(eu_data[[EU]]),]
      ranefs = as.data.frame(ranef(model_fit,condVar=T))
      ranefs$condsd = ranefs$condsd/mean(ranefs$condsd)
      eu_data$EU_std_resid = (ranefs$condval/ranefs$condsd)[match(eu_data[[EU]],ranefs$grp)]
    }
  }
  op = par(mfrow=c(1,2))
  eu_data$sq_std_resids = sqrt(abs(eu_data$EU_std_resid))
  car::qqPlot(eu_data$EU_std_resid,main = 'Plot (EU) Normal Q-Q',pch=19,ylab = 'Observed')  # new qqplot function
  plot(eu_data$fitted,eu_data$sq_std_resids,type='n',main = 'Scale-Location',ylab = expression(sqrt(abs(' deviations '))),xlab = 'Fitted values',ylim = c(0,max(eu_data$sq_std_resids)))
  panel.smooth(eu_data$fitted,eu_data$sq_std_resids)
  par(op)
  invisible(eu_data)
}
```

Here's how to actually make the plots

```{r}
pls205_diagnostics(expression_model,EU = 'Chamber')
```
> Why are there so few points? Our original data had 240 rows?
> Are these plots useful?

Basically, with only 2 EU's per treatment level, there's not a lot we can do in terms of model diagnostics.
The reason that the S/L plot only has two visible points is that with 2 EU/treatment, the residuals ($$y_{ij} - \hat\mu_i$$) are symmetric and so their absolute values are equal.


---------

# Trend analysis
This lab will use the dataset presented in lecture, and already analyzed in Lab 4.

An experiment was run to evaluate effects of increased nitrogen fertilization on tuber yield of Alpine Russet potatoes

- 5 nitrogen regimes: 0, 90, 150, 210, 270 lbs / acre at emergence
- 10 reps / treatment combination
- Response: total yield
  
  
## Load data and inspect
```{r}
alpine_potato = read.csv('~/Desktop/R_Projects/PLS205_Winter2021/PLS205_Winter2021/data/Alpine_Russet_yield.csv')
str(alpine_potato)
```

## Design table

In the previous lab, we analyzed the Treatment as a 5-level categorical variable. 
In this lab, we'll instead model the trend of yield against Nitrogen, 
so treating Nitrogen level as a continuous variable and fitting polynomial functions to describe the shape of the response.
This requires a few modifications of the design table:

**Design**: Completely Randomized Design (CRD)

| Structure | Variable  | Type        | # levels | EU        |
|-----------|-----------|-------------|----------|-----------|
| Treatment | Nitrogen  | Numeric     | 5        | NitrogenF |
| Design    | NitrogenF | Categorical | 5        |           |
|           | Plot      | Categorical | 50       |           |
| Response  | Yield     | Numeric     | 50       |           |


1. In contrast to the table we used in Lab 4, here we declare the Treatment variable "Numeric" 
to denote that we want to model the trend rather than the means of the treatment groups.
2. We add the Nitrogen variable turned into a factor (ie a Categorical variable) as a new Design variable. This represents the specific levels of nitrogen used. We generally have to create this Variable as a new column of our data (see below).
3. The Experimental Unit for the Treatment is now `NitrogenF`, i.e. a categorical variable with a unique category name (level) for each unique value of Nitrogen

The most consequential, and least intuitive part of this new table is having Nitrogen in both the Treatment and Design structure, and it's own Experimental Unit! **Why?** and how do we translate this into an analysis?

The key idea here is that if our goal is a trend analysis, we are intending to extrapolate our conclusions to **new levels of Nitrogen**, 
such as 50, 100, or 250 lbs/acre. 
This means that we have a broader scope than if we had only been interested in comparing the original 5 levels of nitrogen themselves.
The penalty for a broader scope is going to be that the confidence we have in our conclusions is going to be much less (or our precision will be lower).

Generally, a change in scope must be accompanied by a change in the experimental unit. 
Scope is determined by the population of experimental units. In Lab 4, we were interested in comparing N0 to N90 (and others). 
Each of the N0 plots were replicates of the N0 treatment, and each of the N90 plots were replicates of the N90 treatment, and both sets were representative of all potential plots with this level of N0. 

But adding more N0 plots doesn't directly tell us much about what yield would be at N50. 
To learn about N50, it would make more sense to try Nitrogen levels between N0 and N90, rather than increasing replication at those two levels.
So, in a sense, we can consider the 5 Nitrogen levels we've observed as a sample of all possible Nitrogen levels. 
Since we've sampled 5 levels to test, we really have just 5 true replicates of what different Nitrogen levels will do to yield.
All the plots that we've made serve to increase the precision that we measure each of these experimental units, but don't increase the number of different 
Nitrogen levels that we have observed.

## Analysis
The general rules still apply for turning a design table into an analysis:

- Take all Variables under "Treatment" or "Design" that have fewer #levels than the Response, 
add them all as terms in your model, and then declare any experimental units with (1|Variable).

However, with trend analyses, we make two modifications/additions:

1. **Numeric** Treatment (and Design) variables in your table can always be added, even if their # levels equals the Response
2. Polynomial (or other functional forms) can be specified for **Numeric** Treatment (and Design) variables. However, the degree of these functions has to be **less than the number of experimental units for this term**

To apply these rules here, we first have to create the `NitrogenF` term:
```{r}
alpine_potato$NitrogenF = as.factor(alpine_potato$Nitrogen)
str(alpine_potato)
```

Then, we have to decide on a functional form for the Nitrogen effect. 
For simplicity in this class, we'll stick to polynomial-type models, though others like splines may be more useful in general.
With polynomials, the **degree** specifies the wiggliness of the curve. 

- Degree=0 is a flat line
- Degree=1 is a straight line
- Degree=2 is a parabola (1 peak)
- Degree=3 is a cubic function (1 peak and 1 trough)
- and so on

Choosing an appropriate degree is somewhat an art, but lets start with a degree-2 polynomial for now:

```{r}
trend2 = lmer(Yield ~ I(Nitrogen) + I(Nitrogen^2) + (1|NitrogenF), data = alpine_potato)
```

### Diagnostics
The diagnostics for a model with a trend are pretty similar to those of any other model. 
We want to assess the normality within groups and equality of variances across groups of the experimental units.

We can use the new diagnostics function for this, being careful to specify the EUs:

```{r}
pls205_diagnostics(trend2,EU = 'NitrogenF')
```

> Here again, we're probably disappointed to realize that we really have very few EUs to do any diagnostics with!

### Plot the model fit with confidence intervals

It's generally hard to get much sense of the answers of a trend fit from the output of a model itself. 
Plotting the model estimates at a set of candidate values of the predictor (treatment variable) and 
the standard errors of these estimates can be more useful.

First,we first create a new data table to hold the predicted values at different levels of Nitrogen.
We then use `emmeans` to predict the Yield at each intermediate value of Nitrogen.

```{r}
# Create a new data.frame with the set of Nitrogen values we want to plot the trends
predicted_data <- data.frame(Nitrogen = seq(0,300,length=100)) 
```

Get predicted values for the full model using `emmeans()` and append the values to the data.frame
```{r}
trend2_means = emmeans(trend2,spec = 'Nitrogen',at=list(Nitrogen = predicted_data$Nitrogen))
trend2_means_summary = as.data.frame(summary(trend2_means,infer = c(T,F),level = 0.95))
trend2_means_summary
```
> As you can see, at each of the values of Nitrogen, there is a predicted value (emmean) and a lower and upper confidence interval.

Now we can visualize this fit, along with the raw data itself:


Now, we can add these trends to our plot of the data
```{r}
# first, make a base plot with boxplots of the data
base_plot = ggplot(alpine_potato,aes(x=Nitrogen)) + 
    geom_boxplot(aes(y=Yield,group = Nitrogen),color = 'blue',position = position_identity()) + 
    ggtitle('Alpine Russet') + expand_limits(y=0)
# Then, add a line for the trend and a ribbon for the confidence intervals.
# Note, here we have to specify a new data table for the plot to use
base_plot + 
    geom_ribbon(data = trend2_means_summary,aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
    geom_line(data = trend2_means_summary,aes(y = emmean),size=1.5)

```

> You can see that the trend-line is a parabola with a gental curvature centered around 150lbs.
> So the peak is probably our best bet for optimal nitrogen level given our data AND THIS PARTICULAR MODEL
> But also note the size of the confidence intervals! The interpretation here is that we are really pretty uncertain 
about what the yield will be at any particular value of Nitrogen

Maybe this is because the degree-2 polynomial wasn't the right choice? What if we fit a degree-1 or degree-3 polynomial?

Here's the plot for fitting each of these models:
```{r}
trend1 = lmer(Yield ~ I(Nitrogen) + (1|NitrogenF), data = alpine_potato)
trend1_means = emmeans(trend1,spec = 'Nitrogen',at=list(Nitrogen = predicted_data$Nitrogen))
trend1_means_summary = as.data.frame(summary(trend1_means,infer = c(T,F),level = 0.95))
base_plot + ggtitle("Degree-1") + 
    geom_ribbon(data = trend1_means_summary,aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
    geom_line(data = trend1_means_summary,aes(y = emmean),size=1.5)

trend3 = lmer(Yield ~ I(Nitrogen) + I(Nitrogen^2) + I(Nitrogen^3) + (1|NitrogenF), data = alpine_potato)
trend3_means = emmeans(trend3,spec = 'Nitrogen',at=list(Nitrogen = predicted_data$Nitrogen))
trend3_means_summary = as.data.frame(summary(trend3_means,infer = c(T,F),level = 0.95))
base_plot + ggtitle("Degree-3") + 
    geom_ribbon(data = trend3_means_summary,aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
    geom_line(data = trend3_means_summary,aes(y = emmean),size=1.5)

```
> What do you notice about each of these prediction plots? 
> Comment on how well the trends see to fit the data (boxplots) and on the size of the confidence intervals


### Selecting a degree of the trend
We see that we get fairly different conclusions depending on which model we choose. So how should we choose?

There are a couple factors to consider:

1. Higher degree-models will have fewer degrees of freedom for the errors, and so higher critical values for the standard errors.
We started with 5 EU (levels of Nitrogen). A degree-3 fit "eats up" 4 degrees of freedom (intercept, plus 3 powers of Nitrogen).
A degree-2 fit eats up only 3, leafing 2 DF for error. Look at the ANOVAs for the 3 candidate models:
```{r}
cat('degree-1\n')
anova(trend1,ddf = 'K',type='I')
cat('\n')
print('degree-2')
anova(trend2,ddf = 'K',type='I')
cat('\n')
print('degree-3')
anova(trend3,ddf = 'K',type='I')
```
See how in the `trend3` model, the DenDF is only 1? Look at the critical values for models with 1, 2 or 3 degrees of freedom:
```{r}
print('3 Df')
qt(0.05/2,3,lower.tail=F)
cat('\n')
print('2 Df')
qt(0.05/2,2,lower.tail=F)
cat('\n')
print('1 Df')
qt(0.05/2,1,lower.tail=F)
```

> The critical values will be almost 3 times larger going from 1Df to 2Df. So we really don't want to choose a degree only 1 less than the number of EU. Going from 2-3 is much less of a benefit (~1.4x)

But, how about choosing between the degree-2 and degree-1?

Our best bet is to use the ANOVA table of the degree-2 fit:
```{r}
anova(trend2,ddf='K')
```
We first look at the lowest row: `I(Nitrogen^2)`. The F-value measures how much better the model performs with a degree-2 trend than a degree-1 trend (the previous row of the table), relative to the MSE. The p-value does a hypothesis of this statistic against the X^2 coefficient being 0 (the true effect of Nitrogen is actually a straight line).
Here I'd say that even though the p-value is not less than 0.05, the fact that the F-value is very large suggests that we probably should be using a degree-2 trend relative to a degree-1 trend for these data.

### Comparison with analyzing as factors.
The results above are really pretty disappointing. We ran a big experiment with 50 plots with different levels of nitrogen,
and came up with the conclusion that we really can't say very much about what level is best.
The main reason for our failure here is that we only tried 5 levels of nitrogen. We invested a lot in measuring the Yield for these 5 specific levels (using 10 plots for each), but this doesn't translate well into knowing much about the other levels

Let's compare our results above using the degree-2 trend to the results from last lab when we analyzed these 5 specific levels.
Here was that model:

```{r}
factor_model <- lm(Yield ~ NitrogenF, alpine_potato)
factor_means = emmeans(factor_model,specs = 'NitrogenF')
factor_means_summary = as.data.frame(summary(factor_means,infer = c(T,F),level = 0.95))
factor_means_summary$NitrogenF = as.numeric(as.character(factor_means_summary$NitrogenF))

base_plot + 
    geom_ribbon(data = trend2_means_summary,aes(ymin = lower.CL,ymax = upper.CL),alpha = 0.2) + 
    geom_line(data = trend2_means_summary,aes(y = emmean),size=1.5) +
    geom_point(data = factor_means_summary,aes(x = NitrogenF,y = emmean),color = 2,size = 1.5) + 
    geom_errorbar(data = factor_means_summary,aes(x = NitrogenF,ymin = lower.CL,ymax = upper.CL),color = 2,size = 1.5,width = 10) 

```

> Two things to note:
>
> 1. The confidence intervals for the 5 specific levels of Nitrogen are much smaller
> 2. There is some discrepency between the trend model and factor model at the specific tested levels. This suggests that the quadratic thend is not really able to fully capture the effect of Nitrogen on yield. We probably need to be able to fit a model with a higher degree. Unfortunately, our experimental design just really doesn't allow it!

