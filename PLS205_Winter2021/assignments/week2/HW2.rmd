---
title: "HW2"
output:
  html_notebook:
    number_sections: yes
    toc: yes
    toc_float: yes
  html_document:
    df_print: paged
    toc: yes
---

Use this R Notebook document to answer the questions and document your work. 
Enter the R code used to answer each question in the corresponding R code chunk. 
Write any textual explanations **outside** of the chunks. When we grade, we will *hide* the code and just look at the R output and your written answers.
Attempt to clean up your code as much as possible so that only the necessary lines remain. 

When you are done:

1. Select 'Run All' from the 'Run' dropdown menue.
2. Save (File -> Save)
3. Click 'Preview' to bring up the `HW2.nb.html` file. Check through this to make sure it rendered correctly.
4. Upload the files: `HW2.nb.html` and `HW2.Rmd` to Canvas.

---

# Experiment
A researcher is interested in the difference in root growth between two wheat varieties. She plants
16 seeds of each variety in a randomized design and harvests the roots after 1 week. She records
the root length (cm) of each plant.

```{r echo = FALSE}
# This loads the data for this question
data_1 <- read.csv('~/Desktop/R_Projects/PLS205_Winter2021/PLS205_Winter2021/data/wheat_roots.csv')
# This prints a summary of the data table
str(data_1)

data_1$Plant <- as.character(data_1$Plant)
summary(data_1)
```

## Describe the design of this experiment in detail. 

Use the following table. When you click `Preview`, RStudio will format this table into a nice HTML table.
You can also fill out the table in an excel document, and then paste it into [this website](http://www.tablesgenerator.com/markdown_tables) to generate the Markdown table. 

**Design**: Completely randomized design

| Structure | Variable    | Type        | # levels | Experimental Unit |
|-----------|-------------|-------------|----------|-------------------|
| Treatment | Variety     | Character   | 2        |  Plant            |
| Design    | Plant       | Numeric     | 32       |                   |
| Response  | Root Length | Numeric     | 32       |                   |


## To help you analyze this data, I've separated out the data from each variety into a vector:
```{r}
Variety_A <- data_1$Root_length[data_1$Variety == 'A']
Variety_B <- data_1$Root_length[data_1$Variety == 'B']
```

Use these variables below for your calculations.


For the following 4 questions, you can check your answers below with the `t.test` function, but you must write out the calculations by hand. You can use functions like `mean()` and `sd()`, `pt`, `qt`, etc.

## Estimate the difference in root lengths between the two varieties
```{r}
data_1_diff <- mean(Variety_B) - mean(Variety_A)
data_1_diff
```

> The difference in root lengths is 3.47 cm.

## Estimate the standard error of this difference. Assume the variances of the two varieties are the same, and find a pooled estimate of the variance.
```{r, include = FALSE}

# SED

data_1_SED <- sqrt( sd(Variety_A)^2 / 16 + sd(Variety_B)^2 / 16)
data_1_SED


# Variance

# Using var() to determine the variance for Varieties A and B
data_1_var_A <- var(Variety_A)
data_1_var_A
data_1_var_B <- var(Variety_B)
data_1_var_B

# Pooling the variance
data_1_pooled_var <- ((16-1) * data_1_var_A + (16-1) * data_1_var_B) / ((16-1) + (16-1))
data_1_pooled_var
```

> data_1_SED = 0.82 cm

> data_1_pooled_var = 5.34 cm^2

## Form a 90% confidence interval for this difference
```{r, include = FALSE}
SE <- data_1_SED / sqrt(16)
SE

alpha <- 0.1
t_crit = qt(p = 1-alpha/2, df = 16-1)
t_crit

CI <- data_1_diff + c(-t_crit * data_1_SED, t_crit * data_1_SED)
CI
```

> A 90% CI would span from 2.04 cm to 4.90 cm.

## Is it likely to have observed this large a difference by chance if there were actually no difference?
```{r}

```

> Given our p-value (0.0002), it is unlikely that we would have observed this large of a difference if there was actually no difference in root length within the population.

## Repeat the analysis using the `lm` and `emmeans` functions. Do you get the same answer?
```{r, include = FALSE}
library(emmeans)

# lm()

data_1_lm1 <- lm(data_1$Root_length ~ data_1$Variety, data = data_1)
data_1_lm1

# emmeans()

data_1_emmeans_lm1 <- emmeans(data_1_lm1, spec = 'Variety')
data_1_emmeans_diff_lm1 <- contrast(data_1_emmeans_lm1, 'pairwise')

summary(data_1_emmeans_diff_lm1, level = 0.9, infer = c(T, T))
```

> Yes, both the lm() and emmeans() functions return the same difference in means, 3.47 cm.

> The emmeans() function returns the same values, although the CI bounds are slightly narrower (2.08 - 4.86 vs 2.04 - 4.90). I think this may be due to a rounding error.

## Make the model diagnostic plots shown in lab. Is there reason to be concerned about any of the model assumptions?
```{r}
library(ggplot2)

# box and whisker plots
ggplot(data_1,
       aes(x = Variety,
           y = Root_length)) +
  geom_boxplot() + geom_jitter(width = .2)

data_1_lm1_factor <- lm(data_1$Root_length ~ as.factor(data_1$Variety), data = data_1)
data_1_lm1_factor

# model fit
par(mfrow = c(1, 2))
plot(data_1_lm1_factor, which = c(2, 5))

```

> In the first plot (box and whisker plot), Variety B has a larger spread, so we will need to measure whether the apparent differences in mean are significant when compared to the spread of the data.

> In the second plat, residuals of this data matches the line representing the theoretical normal distiribution.

> In the third plot, it looks like the assumptions of normality are met for Variety A, and are plausibly met for Variety B (though there are some gaps). However, as hinted at in the box and whisker plot, Variety B has a larger spread, so we need to take caution with this assumption.

## Calculate the power of the test to detect a difference of 3cm, with n=16 and alpha = 0.1. Assume the within-variety standard deviation is is 2.5cm
```{r, include = FALSE}
# see: ?power.t.test

# SED

data_1_SED_power <- sqrt( (2.5)^2 / 16 + (2.5)^2 / 16)
data_1_SED_power


# Variance

# Using var() to determine the variance for Varieties A and B
data_1_var_A_power <- (2.5)^2
data_1_var_A_power
data_1_var_B_power <- (2.5)^2
data_1_var_B_power

# Pooling the variance
data_1_pooled_var_power <- ((16-1) * data_1_var_A_power + (16-1) * data_1_var_B_power) / ((16-1) + (16-1))
data_1_pooled_var_power

power.t.test(
  n = 16,
  delta = 3,
  sd = sqrt(data_1_pooled_var_power),
  sig.level = 0.1,
  power = NULL,
  type = 'two.sample',
  alternative = 'two.sided'
)

```

> The power is the probability of detecting an effect when there is an effect. So in this experiment, we have a 90% chance of detecting an effect given the above parameters (delta = 3cm, n = 16, alpha = 0.1, sd = 2.5).

## Prepare a table showing the number of replicates required to detect significant differences (alpha = 0.01, power = 0.9) between means that are 1, 2, 4, 8, or 16 cm apart, assuming that the population standard deviation is 4cm. Use the function `power.t.test`. How much easier is it to detect a difference of 16cm than one of 1 cm?
```{r}
delta = c(1,2,4,8,16)

# Here's a hit at how to calculate the sample size for the first delta

reps[1] <- power.t.test(n = NULL,  # make sure to fill in ALL of the ?
                        delta = delta[1],
                        sd = 4,
                        sig.level = 0.01,
                        power = 0.9,
                        type = 'two.sample',
                        alternative = 'two.sided'
                        )$n
reps[2] <- power.t.test(n = NULL,  # make sure to fill in ALL of the ?
                        delta = delta[2],
                        sd = 4,
                        sig.level = 0.01,
                        power = 0.9,
                        type = 'two.sample',
                        alternative = 'two.sided'
                        )$n
reps[3] <- power.t.test(n = NULL,  # make sure to fill in ALL of the ?
                        delta = delta[3],
                        sd = 4,
                        sig.level = 0.01,
                        power = 0.9,
                        type = 'two.sample',
                        alternative = 'two.sided'
                        )$n
reps[4] <- power.t.test(n = NULL,  # make sure to fill in ALL of the ?
                        delta = delta[4],
                        sd = 4,
                        sig.level = 0.01,
                        power = 0.9,
                        type = 'two.sample',
                        alternative = 'two.sided'
                        )$n
reps[5] <- power.t.test(n = NULL,  # make sure to fill in ALL of the ?
                        delta = delta[5],
                        sd = 4,
                        sig.level = 0.01,
                        power = 0.9,
                        type = 'two.sample',
                        alternative = 'two.sided'
                        )$n


reps[1]
reps[2]
reps[3]
reps[4]
reps[5]
reps = c(reps[1:5])

# Here we make a table of the results. 
ans_4.4 <- data.frame(delta,reps)
ans_4.4
```
| mean diff | reps     |
|-----------|----------|
| 1         | 478      |
| 2         | 121      |
| 4         | 31       |
| 8         | 9        |
| 16        | 4        |


> It is much easier to detect a difference of 16 cm. This is evidenced by the number of reps required to detect a difference of 16 cm 90% of the time.