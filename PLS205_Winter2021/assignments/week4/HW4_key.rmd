---
title: "HW4"
output: 
 html_notebook:
    toc: true
    toc_float: true
    number_sections: true
---

> Grading Notes:
>
> For questions that require a text answer:
> Full credit: requires an answer to each question asked. Your explanations need to valid
and logical. You don't need to use the same words as the key, but the meaning needs to be complete.
> Assign partial credit for answers that are incomplete. For multi-part questions, divide points
approximatly equally unless otherwise specified.
>
> For all questions, if you get the right answer using a different approach than I use, that is fine.

> Fill in your scores in the google form here: https://forms.gle/26rGVgmzsgX5oLgW7. 
PLEASE ONLY ENTER A NUMBER. IF YOU WANT TO LEAVE A COMMENT ABOUT A SCORE, DO IT DIRECTLY ON CANVES.
It will require you to log in with your ucdavis email address. Let me know if this causes problems. This way I can associate your grades with you on Canvas


Necessary libraries
```{r echo = F}
library(ggplot2)
library(emmeans)
library(lme4)
library(lmerTest)
library(car)
```

## Question 1

To study the effect of burial time on germination and dormancy of *Hordeum murinum ssp. leporinum* (Hare Barley), 
overwintering seeds were placed in bags in a field, and then removed and tested at six time intervals (0, 30, 60, 90, 180, and 360 days after burial). The design was a completely randomized design, with 5 replicate bags per burial time.
Each bag contained 200 seeds. At the designed time, each bag was opened, and then the seeds were split evenly between two 
germination trays, and the number of germinating seeds was measured in each tray.


```{r echo = FALSE}
# Ensure the data file is in the same directory as this document
germinant_data = read.csv('~/Desktop/R_Projects/PLS205_Winter2021/PLS205_Winter2021/data/Germination.csv')
str(germinant_data)
```

## 1 Describe the design of this experiment in detail.

**Design**: Completely randomized design

| Structure | Variable   | Type        | # levels | Experimental Unit |
|-----------|------------|-------------|----------|-------------------|
| Treatment | Days       | Numeric/Cat | 6        | Bag               |
| Design    | Bag        | Categorical | 30       |                   |
| Design    | Tray       | Categorical | 60       |                   |
| Response  | Germinants | Numeric     | 60       |                   |


> Key things are the experimental unit and the # of levels. It is OK if the names are different
as long as it is clear what each name refers to. The variable Days in the Treatment structure can be type numeric and/or categorical.
> Note: it is reasonable to interpret the description above to say that there are only two total trays that are re-used for all 30 bags. This doesn't change much about the rest of the analysis, except that you would need to include Tray as a term in your models.

> (4 points)


# For the first set of analyses, treat **Days** as a factor

## 2 Use a boxplot to visualize the dose-response curve (ie the number of Germinants observed each Day).
Does there appear to be an effect of age (Date) on number of germinating seeds?

> **Note** For visualization, refer back to the visualization techniques in Lab3 when there were subsamples.
> You should be able to use the same code, just be sure to change all the variable names to match the new dataset
> Be sure to make a new variable called something like `DaysFactor`

```{r}
library(ggplot2)
germinant_data$DaysFactor = factor(germinant_data$Days)
germinant_data$Bag = factor(germinant_data$Bag)
germinant_means = aggregate(Germinants ~ DaysFactor+Bag,germinant_data,FUN = mean)
ggplot(germinant_data,aes(x=DaysFactor,y=Germinants)) + 
  geom_boxplot(data=germinant_means) +  
  geom_point(data = germinant_means,aes(fill = Bag),color = 'red',position = position_jitterdodge(),size = 3) +
  geom_point(data = germinant_data, aes(fill = Bag),position = position_jitterdodge()) + 
  theme(legend.position = 'none') 
```

> Yes, there appears to be a clear effect - longer time leads to much lower germination rates

> [4 points] boxplot should show both raw points and Bag-averages (-1 for missing either). Statement should say something about the apparent effect (direction is good, magnitude would be better)

## 3 Assess whether the linear model assumptions are satisfied by the data.
Treat **Days** as a factor. Use diagnostic plots.

> **Note** Here again, refer to Lab 3 for appropriate diagnostic plots. 
> Again, the same code should work as long as you are careful to change all variable names

```{r}
library(lmerTest)
library(car)
factor_model <- lmer(Germinants~DaysFactor + (1|Bag),germinant_data)

# Step 1: Extract estimates of the experimental unit deviations
eu_data = aggregate(Germinants ~ DaysFactor+Bag,germinant_data,FUN = mean)
  # this is like above - we're generating a new table with one row per plot
  # you'll have to adapt this for other experiments with other Variables
eu_data$deviation = ranef(factor_model)$Bag[eu_data$Bag,1] 
  # The key above is to substitute `Plot` for the name of your random experimental unit term above in both places
eu_data$fitted = predict(factor_model,newdata = eu_data,re.form = ~0)
  # This line you can use directly

# Step 2: Make QQplot and `Scale-Location` plot:
op = par(mfrow=c(1,2))  # two plots side-by-side
qqPlot(eu_data$deviation,main = 'Plot (EU) Normal Q-Q',pch=19)  # new qqplot function
scatter.smooth(eu_data$fitted,sqrt(abs(eu_data$deviation)),span = 1,main = 'Scale-Location',ylab = expression(sqrt(abs(' deviations '))),xlab = 'Fitted values')
```

> Yes, the residuals are consistent with a normal distribution, and variances appear approximately equal in each group.

> You need to show both the QQ-plot and a plot that shows the variances between groups (scale-location, boxplot, residuals vs. fitted values, etc.)

> (4 points): 2 points for QQ-plot and 2 points for a plot that shows variances between groups.



## 4 Test (provide p-values as evidence) if any of extended germination times change germination rate relative to zero days

> **Note** Refer to Lab3 for correct usage of `emmeans()` with `lmer()` models.

```{r}
library(emmeans)
factor_means = emmeans(factor_model,specs = 'DaysFactor', lmer.df = 'K')
factor_differences <- contrast(factor_means,'trt.vs.ctrl',ref=1)
summary(factor_differences,infer=c(F,T))

```


> Yes, there is strong evidence of an effect for all times after 30 days.

> We are looking for pairwise comparisons with 0 days using emmeans.

> (4 points)


## 5 Use an ANOVA to assess the evidence for any effect of time germination rate
Is there strong evidence for a difference in germination rate by seed age?

> **Note**. The ANOVA table produced by the `lmer()` function looks a bit different from that of the `lm()` function.
> But all the same information is there, and it should be clear how to interpret
> You should add the argument `ddf = 'Kenward-Roger'` (or abbreviation `ddf='K'` whenever you do `anova()` with a `lmer()` model

```{r}
anova(factor_model,ddf = 'Kenward-Roger',type='I')
```


> Yes - treating Days as a factor and testing if any treatment (Date) is different than any other
in an ANOVA, we find very strong evidence against H0 (no effect).

> (4 points) 

## 6 Explain the following features of the ANOVA table

1. The Df of the treatment and Experimental Units
2. The ANOVA table doesn't report the MSE, but you can calculate it. Is it the correct number?
     - Hint: try fitting the model incorrectly by forgetting to declare the experimental units. Look at an ANOVA of this model. 
     Can you figure out what the MSE is that's reported by the "correct" ANOVA table? Why is this the wrong MSE? 
     Note: the F-value and p-value of the ANOVA table from the correctly specific model is correct, but the MST and MSE have a different meaning. This is unfortunate, but we'll have to live with it!

> 1:
> Degrees of freedom
> DfT = 6-1 (6 different lengths of times). DfE = 6*(5-1) = 24 (6 treatments, each with 5 reps). 2 point for df of treatment and 2 point for df of residuals for 2 points total.
> You can also give a conceptual explanation for degrees of freedom. For instance, df of the treatment is k - 1 and df of the residuals is k x (n - 1). 
> (4 points)

> 2:
> The F-value in the ANOVA is MST/MSE. So 37.678 = 887.95/MSE, which gives MSE = 23.57.
> However, look back at the table of treatment effects by emmeans above. The SE of a difference is 
> 5.15 = sqrt(s2_eu/n1 + s2_eu/n2) = sqrt(2*(s2_eu/5)), from which we can calculate s2_eu = MSE = 66.3
> But, look at the ANOVA if we forget to declare Bags as an EU:

```{r}
anova(lm(Germinants~DaysFactor+Bag,germinant_data))
```
> The MSE is exactly the MSE calculated from our "correct" ANOVA above. This means we have to be very careful with these ANOVA tables. The p-value from the "correct" table is correct, as is the F-ratio. These are both wrong in the table from the "wrong" model. But we need to rely on emmeans to calculate the actual MSE and SED, not take it from the ANOVA itself.

>[1 point] for any attempt

# Question 2

A researcher conducted a study comparing the effect of different ground covers on nitrous oxide fluxes from apple orchard soils. She randomly assigned the inter-row spaces of an orchard block to one of four treatments: 1) no cover (Bare); 2) fescue (Grass); 3) white clover (Legume); and, 4) fescue-clover mix (Mix). Each treatment level was replicated in 6 plots. After rain events, emissions were collected from each plot, analyzed, and the emitted nitrous oxide was calculated in g N~2~O ha^-1^ d^-1^. Average emissions for each plot are reported below.

| Rep |  Bare | Grass | Legume |  Mix  |
|:---:|:-----:|:-----:|:------:|:-----:|
|  1  | 44.79 | 21.59 |  20.08 | 21.48 |
|  2  | 53.71 | 21.58 |  16.76 | 24.46 |
|  3  | 68.69 | 25.73 |  15.15 | 25.47 |
|  4  | 70.46 | 32.08 |  17.72 | 27.02 |
|  5  | 88.11 | 27.60 |  15.13 | 18.52 |
|  6  | 95.53 | 22.11 |  19.98 | 21.54 |

```{r echo=FALSE}
NO_data = read.csv('NO_data.csv')
str(NO_data)
```

## 1 Describe the design of this experiment in detail.

**Design**: Completely randomized design

| Structure | Variable   | Type        | # levels | Experimental Unit |
|-----------|------------|-------------|----------|-------------------|
| Treatment | Cover      | Categorical | 4        | Plot              |
| Design    | Plot       | Categorical | 24       |                   |
| Response  | Flux       | Numeric     | 24       |                   |

> Key things are the experimental unit and the # of levels. It is OK if the names are different
as long as it is clear what each name refers to. 

> (4 points)


## 2 Test the necessary assumptions of ANOVA. Report on the results.

```{r}
par(mfrow=c(1,2))
lm1 = lm(Flux ~ Cover,NO_data)
plot(lm1,which=c(2,3))
```

> We see a strong signal of increased variance for larger means (Scale-Locaiton plot) We also see large outliers in both the positive and negative direction (Normal QQ plot). 
Both demonstrate failure of ANOVA assumptions. However, the increase of variance with the mean suggests a log transform may be appropriate

> (6 points) Needs to interpret the deviations in both plots (3 each)


## 3 Perform an appropriate transformation of the data. Re-check the assumptions of ANOVA, and report the results.

```{r}
lm_log2 = lm(log2(NO_data$Flux) ~ Cover,NO_data)
par(mfrow=c(1,2))
plot(lm_log2,which=c(2,3))
```

> After log2 transforming, the Normal Q-Q plot shows not deviation from normality. The Scale-Location plot shows some mild increase in variance of larger means, but much less severe than before transforming. 

> These diagnostic plots would look identical if the log() or log10() functions were used instead. The power transformation would be acceptable too, but power transformations do not lead to as clear conclusions as log transformations.

> (5 points). Log, sqrt, or Power could be used (3 points). The plots should be shown and discussed (2 points)


## 4 Provide estimates of effects of the various ground covers relative to Bare ground on both the original and transformed data ($\alpha = 0.05$). 
Describe and compare the results of both models. Be sure to provide units for the effect sizes on both scales.

```{r}
Flux_means_original = emmeans(lm1,specs = 'Cover')
summary(contrast(Flux_means_original,method='trt.vs.ctrl'),level = 0.95,infer = c(T,T))
```
```{r}
Flux_means_log2 = emmeans(lm_log2,specs = 'Cover')
summary(contrast(Flux_means_log2,method='trt.vs.ctrl'),level = 0.95,infer = c(T,T))
```

> Both with and without transformations, we find that all treatments were significantly different from the control. 

> The effect sizes on the un-transformed scales are differences in means (units = gN20 /ha/d). The interpretation is:
The grass treatment resulted in a decrease of 45g N20 /ha/d (CI: decrease of 30-60 g).

> The effect sizes on the log2-transformed scales are log2(multiplicative factors), or log2-fold changes. The interpretation is:
The grass treatment resulted in a decrease of N20 /ha/d by a factor of 2^-1.45 = 0.37, or about 1.5 halvings of the N20 emmision rate.

> If the log-transformation was used, the interpretation would be:
The grass treatment resulted in a decrease of N20 /ha/d by a factor of e^-1.0 = 0.37. 
Since this log(fold-change) is bigger than ~0.2-0.3, the approximation of delta as percent change is not very accurate.

> (5 points) trt.vs.ctrl contasts should be used (2 points). Conclusions should be made for both analyses with appropriate units (3 points). If sqrt or power transformations were used, then no units are possible on the transformed scale. 


## 5 Provide estimates and confidence intervals for the means of the 4 treatment.
**Are the means greater or less than the means estimated on the un-transformed scale?**

```{r}
transformed_estimates = as.data.frame(Flux_means_log2)
transformed_estimates$De_trans_estimate = 2^(transformed_estimates$emmean)
transformed_estimates$De_trans_lower.CL = 2^(transformed_estimates$lower.CL)
transformed_estimates$De_trans_upper.CL = 2^(transformed_estimates$upper.CL)
transformed_estimates[,c('De_trans_estimate','De_trans_lower.CL','De_trans_upper.CL')]

as.data.frame(Flux_means_original)[,c('emmean','lower.CL','upper.CL')]

# or simpler:
summary(Flux_means_log2,type='response')
```

> De-transformed means after a log transformation are always lower than the means on the un-transformed scale. The name of these values is the "geometric mean"

> (5 points) The de-transformation should be correct and complete (both means and CIs 3 points). The comparison with un-transformated means (2 points)
